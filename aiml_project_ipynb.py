# -*- coding: utf-8 -*-
"""AIML project ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvGgwJKjrngJ1IsT8xdVz7S8Mfi2dNae

#Student Mental Stress prediction
"""

#Step 1Ô∏è: Load and Clean Both Datasets

import pandas as pd

# Step 1Ô∏è: Load both datasets
df1 = pd.read_csv("Student Stress Factors (2).csv")
df2 = pd.read_csv("Stress (Responses) - Form Responses 1.csv")

# Step 2Ô∏è: Clean column names (remove hidden spaces or extra chars)
df1.columns = df1.columns.str.strip()
df2.columns = df2.columns.str.strip()

# Step 3Ô∏è: Rename columns for clarity and consistency
df1.columns = ['SleepQuality', 'Headache', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']

df2 = df2.rename(columns={
    'Sleep Hours per Day': 'SleepQuality',
    'Number of Extracurricular Activity': 'Extracurricular',
    'Study Hours Per Day': 'StudyLoad',
    'Academic Score / CGPA': 'AcademicPerf',
    'Self-assessed Stress Level': 'StressLevel'
})

# Preview both datasets
print("\n===== Dataset 1 (Student Stress Factors) =====")
print(df1.head())

print("\n===== Dataset 2 (Stress Responses) =====")
print(df2.head())

# Step 4Ô∏è: Display column names to verify renaming
print("\n Columns after renaming:")
print(df1.columns.tolist())
print(df2.columns.tolist())

# Step 5Ô∏è: Convert 1‚Äì10 scale to 1‚Äì5 scale for relevant numeric columns
cols_to_scale = ['SleepQuality', 'StudyLoad', 'Extracurricular', 'AcademicPerf']

for col in cols_to_scale:
    if col in df2.columns:
        df2[col] = (df2[col] / 2).round().clip(1, 5)

# Step 6Ô∏è: Encode stress levels (Low / Medium / High ‚Üí 1 / 3 / 5)
stress_map = {'Low': 1, 'Medium': 3, 'High': 5}
df2['StressLevel'] = df2['StressLevel'].map(stress_map)

# Step 7Ô∏è: Handle missing or unmapped stress levels
df2 = df2.dropna(subset=['StressLevel'])

# Step 8Ô∏è: Select common columns to merge
df1_final = df1[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']]
df2_final = df2[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']]

# Step 9Ô∏è: Combine both datasets
combined_df = pd.concat([df1_final, df2_final], ignore_index=True)

# Step 10: Display summary info and preview
print("\n Combined Dataset Info:")
print(combined_df.info())
print("\n Preview of Combined Data:")
print(combined_df.head())

# Step 11 : Save combined dataset
combined_df.to_csv("Combined_Student_Stress.csv", index=False)
print("\nCombined dataset saved successfully as 'Combined_Student_Stress.csv'")

#download combined file
from google.colab import files
files.download("Combined_Student_Stress.csv")

print(combined_df.shape)

print("Second dataset rows before merge:", len(df2))
print("After selecting common columns:", len(df2_final))
print(df2_final.head())

# Combine Student Stress Datasets Safely

import pandas as pd

# Step 1Ô∏è: Load both datasets
df1 = pd.read_csv("Student Stress Factors (2).csv")
df2 = pd.read_csv("Stress (Responses) - Form Responses 1.csv")

# Step 2Ô∏è: Clean all column names (remove extra spaces, hidden chars)
df1.columns = df1.columns.str.strip()
df2.columns = df2.columns.str.strip()

# Step 3Ô∏è: Rename columns for clarity and alignment
df1.columns = ['SleepQuality', 'Headache', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']

df2 = df2.rename(columns={
    'Sleep Hours per Day': 'SleepQuality',
    'Number of Extracurricular Activity': 'Extracurricular',
    'Study Hours Per Day': 'StudyLoad',
    'Academic Score / CGPA': 'AcademicPerf',
    'Self-assessed Stress Level': 'StressLevel'
})

# Step 4Ô∏è: Verify rename worked
print("\ndf2 columns after cleaning:")
print(df2.columns.tolist())

# Step 5Ô∏è: Handle possible 1‚Äì10 scale in df2 (convert to 1‚Äì5 scale)
cols_to_scale = ['SleepQuality', 'StudyLoad', 'Extracurricular', 'AcademicPerf']
for col in cols_to_scale:
    if col in df2.columns:
        df2[col] = (df2[col] / 2).round().clip(1, 5)

# Step 6Ô∏è: Clean and map text-based stress levels
if df2['StressLevel'].dtype == 'object':
    df2['StressLevel'] = df2['StressLevel'].astype(str).str.strip().str.capitalize()

stress_map = {
    'Low': 1,
    'Medium': 3,
    'High': 5

}
df2['StressLevel'] = df2['StressLevel'].map(stress_map)

# Step 7Ô∏è: Debug ‚Äî check unmapped entries before dropping
print("\n Check StressLevel mapping (NaN means unmapped):")
print(df2['StressLevel'].value_counts(dropna=False))

# Step 8Ô∏è: Drop only if StressLevel missing
df2 = df2.dropna(subset=['StressLevel'])

# Step 9Ô∏è: Select matching columns for merge
df1_final = df1[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']]
df2_final = df2[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular', 'StressLevel']]

# Step 10: Combine both datasets
combined_df = pd.concat([df1_final, df2_final], ignore_index=True)

# Step 11: Verify merge success
print("\n Combined dataset shape:", combined_df.shape)
print(" Expected rows ‚âà", len(df1_final) + len(df2_final))
print("\n Sample of Combined Data:")
print(combined_df.sample(10))

# Step 12: Save combined dataset
combined_df.to_csv("Combined_Student_Stress.csv", index=False)
print("\nCombined dataset saved successfully as 'Combined_Student_Stress.csv'")

from google.colab import files
files.download("Combined_Student_Stress.csv")

"""Perform EDA (Exploratory Data Analysis)

Correlation heatmap

Distribution plots for features

Relationship of stress vs. study load, sleep, etc.
"""

combined_df = pd.read_csv("Combined_Student_Stress.csv")
print(combined_df.shape)

"""Correlation Heatmap ‚Äî to see how features relate to stress levels."""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
sns.heatmap(combined_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap: Features vs Stress Level", fontsize=14)
plt.show()

"""üß† What This Correlation Heatmap Shows

Each cell in the heatmap represents the Pearson correlation coefficient (ranging from -1 to +1) between two features.

+1 ‚Üí Strong positive relationship (they rise together)

-1 ‚Üí Strong negative relationship (one rises as the other falls)

0 ‚Üí No linear relationship

key Insight Summary

Study Load is the strongest driver of student stress (r = 0.35).

Sleep Quality shows a weak but positive relationship ‚Äî possibly due to reversed rating scale or self-perception bias.

Academic Performance and Extracurricular Activities show minimal direct effect on stress, indicating stress is more influenced by workload than outcomes or hobbies.

Correlation Analysis:

A correlation heatmap was generated to examine relationships between variables.
 The analysis revealed a moderate positive correlation (r = 0.35) between Study Load and Stress Level, indicating that heavier workloads contribute to higher stress. Other factors such as Sleep Quality, Academic Performance, and Extracurricular Involvement showed weaker correlations..
 suggesting that stress levels are influenced by workload intensity rather than lifestyle or academic performance.
"""

#Distribution Plots for Each Feature

import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set(style="whitegrid")

# Create subplots for all features
combined_df.hist(figsize=(10,6), bins=10, color="#3b8ed6", edgecolor="black")
plt.suptitle("Feature Distributions in Combined Dataset", fontsize=16)
plt.show()

"""SleepQuality ‚Üí Often centered around 2‚Äì4 (suggesting average to good sleep quality among students).

AcademicPerf ‚Üí Balanced spread ‚Äî no extreme outliers, indicating varied performance levels.

StudyLoad ‚Üí Slight right skew ‚Äî many students have moderate to high workload.

Extracurricular ‚Üí Lower participation overall (peaks near 1‚Äì3).

StressLevel ‚Üí Likely right-skewed ‚Äî more students report medium to high stress levels.

The majority of students exhibit moderate stress levels and average sleep quality. A significant proportion report higher study loads, supporting the correlation between workload and stress.
"""

#Relationship Between Study Load & Stress Level

plt.figure(figsize=(7,5))
sns.boxplot(x='StudyLoad', y='StressLevel', data=combined_df, palette="coolwarm")
plt.title("Relationship: Study Load vs Stress Level", fontsize=13)
plt.xlabel("Study Load (1 = Light, 5 = Heavy)")
plt.ylabel("Stress Level (1 = Low, 5 = High)")
plt.show()

"""Interpretation:

The median stress level rises as StudyLoad increases.

Students with a StudyLoad ‚â• 4 show higher stress variability, meaning not all cope equally with heavy workloads.

Report Insight:

There‚Äôs a clear upward trend ‚Äî students reporting higher study loads experience proportionally higher stress. This validates the workload as the primary predictive feature for stress.
"""

#Relationship Between Sleep Quality & Stress Level

plt.figure(figsize=(7,5))
sns.boxplot(x='SleepQuality', y='StressLevel', data=combined_df, palette="Greens")
plt.title("Relationship: Sleep Quality vs Stress Level", fontsize=13)
plt.xlabel("Sleep Quality (5 = Poor, 1 = Excellent)")
plt.ylabel("Stress Level (1 = Low, 5 = High)")
plt.show()

"""Relationship Between Sleep Quality and Stress:


A boxplot was used to visualize how students‚Äô sleep quality influences their stress levels. The plot shows that students with higher sleep quality (rating 5) still exhibit moderate to high stress, suggesting that sleep alone may not significantly reduce stress in this group. However, the wide variability among students with poor sleep (ratings 1‚Äì2) indicates inconsistent stress responses, implying that other behavioral or environmental factors influence stress more strongly than sleep quality alone.
"""

#Relationship Between Academic Performance & Stress Level

plt.figure(figsize=(7,5))
sns.boxplot(x='AcademicPerf', y='StressLevel', data=combined_df, palette="Purples")
plt.title("Relationship: Academic Performance vs Stress Level", fontsize=13)
plt.xlabel("Academic Performance (1 = Poor, 5 = Excellent)")
plt.ylabel("Stress Level (1 = Low, 5 = High)")
plt.show()

"""Academic Performance vs Stress Analysis:


The relationship between academic performance and stress levels revealed a non-linear trend. Students with average to high academic performance exhibited moderate to high stress levels, possibly due to competition and performance pressure. Conversely, students with lower academic performance reported lower median stress but showed greater variability, suggesting mixed emotional responses among low achievers.
"""

#Relationship Between Extracurricular Activities & Stress Level

#plt.figure(figsize=(7,5))
sns.boxplot(x='Extracurricular', y='StressLevel', data=combined_df, palette="Oranges")
plt.title("Relationship: Extracurricular Activities vs Stress Level", fontsize=13)
plt.xlabel("Extracurricular Frequency (1 = None, 5 = Very Frequent)")
plt.ylabel("Stress Level (1 = Low, 5 = High)")
plt.show()

"""Preapare data for Training

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load dataset
combined_df = pd.read_csv("Combined_Student_Stress.csv")
print(combined_df.shape)

# Features (X) and Target (y)
X = combined_df[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular']]
y = combined_df['StressLevel']

# Split data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data for better model performance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#Train Regression Model

Prepares features/target

Trains: Linear Regression, Multiple Linear Regression (same as linear with multiple features), Polynomial Regression (degree 2), Ridge, Lasso, Support Vector Regression (SVR), Decision Tree Regression, Random Forest Regression

Evaluates each model (R¬≤, RMSE, MAE)

Shows predicted vs actual plots for top models

Shows feature importances & linear coefficients
"""

# 1) LOAD DATA
file_path = "Combined_Student_Stress.csv"
df = pd.read_csv(file_path)
print("Loaded dataset shape:", df.shape)
display(df.head())

#  2) PREPARE FEATURES & TARGET
features = ['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular']
for f in features:
    if f not in df.columns:
        raise ValueError(f"Feature '{f}' not found in dataset. Check your CSV column names.")

"""#Simple regression

using StudyLoad variable
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


# 1. LOAD DATA
df = pd.read_csv("Combined_Student_Stress.csv")

# Choose ONE feature for simple regression
x = df['StudyLoad'].values     #independent
y = df['StressLevel'].values   #dependent


# 2. CALCULATE SLOPE & INTERCEPT MANUALLY

x_mean = np.mean(x)
y_mean = np.mean(y)

# formula: b1 = Œ£(x-mean)(y-mean) / Œ£(x-mean)^2
b1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean)**2)

# formula: b0 = mean(y) - b1 * mean(x)
b0 = y_mean - b1 * x_mean

print(f"Regression Equation:")
print(f"StressLevel = {b0:.3f} + {b1:.3f} * StudyLoad")

# 3. MAKE PREDICTIONS

y_pred = b0 + b1 * x


# 4. MODEL EVALUATION (R¬≤)

ss_total = np.sum((y - y_mean)**2)
ss_res = np.sum((y - y_pred)**2)
r2 = 1 - (ss_res / ss_total)

rmse = np.sqrt(np.mean((y - y_pred)**2))

print(f"\nR¬≤ Score: {r2:.3f}")
print(f"RMSE: {rmse:.3f}")


# 5. PLOT

plt.scatter(x, y, color='blue', label="Actual Data")
plt.plot(x, y_pred, color='red', label="Regression Line")
plt.xlabel("Study Load")
plt.ylabel("Stress Level")
plt.title("Simple Linear Regression (Study Load ‚Üí Stress)")
plt.legend()
plt.show()

"""#Multiple Regression

'SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular'
"""

# 1. LOAD DATA
df = pd.read_csv("Combined_Student_Stress.csv")

# Select features (X) and target (y)
X = df[['SleepQuality', 'AcademicPerf', 'StudyLoad', 'Extracurricular']].values
y = df['StressLevel'].values.reshape(-1, 1)

# Add bias column (intercept term)
# X_b = [1  x1  x2  x3  x4]
X_b = np.c_[np.ones((X.shape[0], 1)), X]

# 2. NORMAL EQUATION FORMULA
#    Œ∏ = (X·µÄ X)‚Åª¬π X·µÄ y

theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)

print("\nMultiple Regression Coefficients:")
print("-----------------------------------")
print(f"Intercept (b0): {theta[0][0]:.4f}")
print(f"SleepQuality (b1): {theta[1][0]:.4f}")
print(f"AcademicPerf (b2): {theta[2][0]:.4f}")
print(f"StudyLoad (b3): {theta[3][0]:.4f}")
print(f"Extracurricular (b4): {theta[4][0]:.4f}")


# 3. PREDICTION
y_pred = X_b.dot(theta)


# 4. MODEL EVALUATION

ss_total = np.sum((y - np.mean(y))**2)
ss_res   = np.sum((y - y_pred)**2)

r2 = 1 - (ss_res / ss_total)
rmse = np.sqrt(np.mean((y - y_pred)**2))

print("\nModel Performance:")
print("----------------------")
print(f"R¬≤ Score: {r2:.4f}")
print(f"RMSE: {rmse:.4f}")


# 5. PLOT ACTUAL vs PREDICTED
plt.figure(figsize=(6,6))
plt.scatter(y, y_pred, color='blue')
plt.plot([1,5], [1,5], 'r--')
plt.xlabel("Actual Stress Level")
plt.ylabel("Predicted Stress Level")
plt.title("Actual vs Predicted Stress (Multiple Linear Regression)")
plt.show()

"""#Polynomial Regression ( degree 2)

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 1. Load Data

df = pd.read_csv("Combined_Student_Stress.csv")

# Choose one feature for polynomial regression
x = df["StudyLoad"].values.reshape(-1, 1)
y = df["StressLevel"].values.reshape(-1, 1)


# 2. Create Polynomial Features Manually
#    X_poly = [1, x, x^2]
x1 = x
x2 = x ** 2

# Combine them to create design matrix
X_poly = np.hstack([np.ones((len(x), 1)), x1, x2])


# 3. Compute Polynomial Coefficients Using Normal Equation
#    Œ∏ = (X·µÄ X)‚Åª¬π X·µÄ y

theta = np.linalg.inv(X_poly.T @ X_poly) @ (X_poly.T @ y)

b0 = theta[0][0]
b1 = theta[1][0]
b2 = theta[2][0]

print("Polynomial Regression Equation:")
print(f"StressLevel = {b0:.4f} + {b1:.4f}*StudyLoad + {b2:.4f}*(StudyLoad^2)")


# 4. Predictions

y_pred = X_poly @ theta

# 5. Evaluation Metrics

ss_total = np.sum((y - np.mean(y)) ** 2)
ss_res   = np.sum((y - y_pred) ** 2)
r2 = 1 - (ss_res / ss_total)
rmse = np.sqrt(np.mean((y - y_pred)**2))

print("\Model Performance:")
print(f"R¬≤ Score: {r2:.4f}")
print(f"RMSE: {rmse:.4f}")


# 6. Plot

plt.scatter(x, y, color="blue", label="Actual Data")
sorted_idx = np.argsort(x.flatten())
plt.plot(x.flatten()[sorted_idx], y_pred.flatten()[sorted_idx],
         color="red", linewidth=2, label="Polynomial Fit (Degree 2)")
plt.xlabel("Study Load")
plt.ylabel("Stress Level")
plt.title("Polynomial Regression (From Scratch) - StudyLoad ‚Üí Stress")
plt.legend()
plt.show()

"""#Regression Tree (Decision Tree Regression) for Stress Prediction


Features (X):

SleepQuality

AcademicPerf

StudyLoad

Extracurricular

Target (y):

StressLevel (1‚Äì5)
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import numpy as np

# Load Dataset
df = pd.read_csv("Combined_Student_Stress.csv")

# Select features & target
X = df[["SleepQuality", "AcademicPerf", "StudyLoad", "Extracurricular"]]
y = df["StressLevel"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
# Create Regression Tree
reg_tree = DecisionTreeRegressor(max_depth=4, random_state=42)

# Train the model
reg_tree.fit(X_train, y_train)

# Predictions
y_pred = reg_tree.predict(X_test)

# Evaluation metrics
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Regression Tree Performance")
print("------------------------------")
print("R¬≤ Score:", round(r2, 3))
print("RMSE:", round(rmse, 3))
plt.figure(figsize=(18, 10))
plot_tree(
    reg_tree,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree Regression (Stress Prediction)")
plt.show()

"""#Random Forest Regression"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("Combined_Student_Stress.csv")

# Features and target
X = df[["SleepQuality", "AcademicPerf", "StudyLoad", "Extracurricular"]]
y = df["StressLevel"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# 1) Regression Tree

tree_model = DecisionTreeRegressor(max_depth=4, random_state=42)
tree_model.fit(X_train, y_train)

y_pred_tree = tree_model.predict(X_test)

r2_tree = r2_score(y_test, y_pred_tree)
rmse_tree = np.sqrt(mean_squared_error(y_test, y_pred_tree))


# 2) Random Forest

rf_model = RandomForestRegressor(
    n_estimators=200,
    max_depth=6,
    random_state=42
)

rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

r2_rf = r2_score(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))


# Comparison Table

comparison = pd.DataFrame({
    "Model": ["Decision Tree Regression", "Random Forest Regression"],
    "R¬≤ Score": [r2_tree, r2_rf],
    "RMSE": [rmse_tree, rmse_rf]
})

print("\nModel Comparison Summary:")
print(comparison)


# Feature Importance Plot (Random Forest)

importances = rf_model.feature_importances_
plt.figure(figsize=(7,4))
plt.bar(X.columns, importances, color='teal')
plt.title("Feature Importance (Random Forest)")
plt.ylabel("Importance Score")
plt.show()

"""Random Forest significantly improves prediction accuracy by aggregating multiple decision trees trained on random subsets of data and features.
This reduces variance and stabilizes predictions.

# compare model
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# All model performance values you provided
comparison = pd.DataFrame({
    "Model": [
        "Simple Linear Regression",
        "Multiple Linear Regression",
        "Polynomial Regression (Degree 2)",
        "Decision Tree Regression",
        "Random Forest Regression"
    ],
    "R¬≤ Score": [
        0.121,   # simple regression
        0.136,   # multiple regression
        0.146,   # polynomial
        0.372,   # decision tree
        0.684    # random forest
    ],
    "RMSE": [
        1.257,    # simple regression
        1.2467,   # multiple regression
        1.2394,   # polynomial
        1.0957,   # decision tree
        0.777     # random forest
    ]
})

comparison

#Bar Chart ‚Äî R¬≤ Score Comparison

plt.figure(figsize=(10,5))
sns.barplot(data=comparison, x="Model", y="R¬≤ Score", palette="viridis")

plt.title("Regression Model Comparison (R¬≤ Score)", fontsize=14)
plt.ylabel("R¬≤ Score")
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.show()

#Bar Chart ‚Äî RMSE Comparison
plt.figure(figsize=(10,5))
sns.barplot(data=comparison, x="Model", y="RMSE", palette="magma")

plt.title("Regression Model Comparison (RMSE)", fontsize=14)
plt.ylabel("RMSE (Lower is better)")
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.show()

"""# Combined chart"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Your model performance data
comparison = pd.DataFrame({
    "Model": [
        "Simple Linear Regression",
        "Multiple Linear Regression",
        "Polynomial Regression (Degree 2)",
        "Decision Tree Regression",
        "Random Forest Regression"
    ],
    "R¬≤ Score": [
        0.121,
        0.136,
        0.146,
        0.372,
        0.684
    ],
    "RMSE": [
        1.257,
        1.2467,
        1.2394,
        1.0957,
        0.777
    ]
})

# Convert RMSE so higher bar = better performance
# (Because lower RMSE is better ‚Üí invert it)
comparison["RMSE (Inverted)"] = comparison["RMSE"].max() - comparison["RMSE"]


plt.figure(figsize=(12,6))

# Melt the dataframe
df_melt = comparison.melt(id_vars="Model",
                          value_vars=["R¬≤ Score", "RMSE (Inverted)"],
                          var_name="Metric",
                          value_name="Value")

sns.barplot(x="Model", y="Value", hue="Metric", data=df_melt, palette="Set2")

plt.title("Combined Comparison of Regression Models (R¬≤ & RMSE)", fontsize=16)
plt.xlabel("Model")
plt.ylabel("Performance Score (Higher is Better)")
plt.xticks(rotation=40, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.legend(title="Metric")
plt.tight_layout()
plt.show()

"""# Best Model : Random Forest Regression

#Train Classification Model

1. Logistic Regression
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


# 1. Load Dataset

df = pd.read_csv("Combined_Student_Stress.csv")

# Convert to binary classification:
# High stress (4,5) = 1
# Low/medium stress (1,2,3) = 0
df["StressBinary"] = (df["StressLevel"] >= 4).astype(int)

# Choose features (use two or more)
X = df[["SleepQuality", "AcademicPerf", "StudyLoad", "Extracurricular"]].values
y = df["StressBinary"].values.reshape(-1, 1)

# Normalize features (important for gradient descent)
X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)

# Add bias term
X_b = np.c_[np.ones((X.shape[0], 1)), X]


# 2. Sigmoid Function

def sigmoid(z):
    return 1 / (1 + np.exp(-z))


# 3. Logistic Regression using Gradient Descent

def logistic_regression(X, y, lr=0.01, iterations=5000):
    m, n = X.shape
    theta = np.zeros((n, 1))  # weights

    costs = []

    for i in range(iterations):
        z = X.dot(theta)
        h = sigmoid(z)

        # Loss (Binary Cross Entropy)
        cost = -(1/m) * np.sum(y*np.log(h+1e-9) + (1-y)*np.log(1-h+1e-9))
        costs.append(cost)

        # Gradient Descent
        gradient = (1/m) * X.T.dot(h - y)
        theta -= lr * gradient

    return theta, costs

# Train model
theta, costs = logistic_regression(X_b, y)

print("Training Complete!")
print("Weights (theta):")
print(theta.flatten())


# 4. Prediction & Accuracy

def predict(X, theta):
    return (sigmoid(X.dot(theta)) >= 0.5).astype(int)

y_pred = predict(X_b, theta)

accuracy = np.mean(y_pred == y)
print(f"\nModel Accuracy: {accuracy*100:.2f}%")


# 5. Plot Loss Curve

plt.plot(costs)
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.title("Logistic Regression Training Loss")
plt.show()

"""Logistic Regression (2 Features) + Decision Boundary (No Library)"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load Data
df = pd.read_csv("Combined_Student_Stress.csv")

# Binary target
df["StressBinary"] = (df["StressLevel"] >= 4).astype(int)

# Select TWO features for decision boundary
X = df[["StudyLoad", "SleepQuality"]].values
y = df["StressBinary"].values.reshape(-1, 1)

# Normalize features
X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)

# Add bias term
X_b = np.c_[np.ones((X.shape[0], 1)), X]

# Sigmoid
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Logistic Regression (Gradient Descent)
def logistic_regression(X, y, lr=0.05, iterations=3000):
    m, n = X.shape
    theta = np.zeros((n, 1))
    costs = []

    for i in range(iterations):
        h = sigmoid(X.dot(theta))
        cost = -(1/m) * np.sum(y*np.log(h+1e-9) + (1-y)*np.log(1-h+1e-9))
        gradient = (1/m) * X.T.dot(h - y)
        theta -= lr * gradient
        costs.append(cost)

    return theta, costs

theta, costs = logistic_regression(X_b, y)


# PLOT: Logistic Regression Decision Boundary

plt.figure(figsize=(8, 6))

# Scatter actual points
plt.scatter(X[:,0], X[:,1], c=y.flatten(), cmap="coolwarm", s=60)

# Create meshgrid
x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1
y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),
                     np.linspace(y_min, y_max, 200))

# Predict over grid
grid_points = np.c_[np.ones((xx.size, 1)), xx.ravel(), yy.ravel()]
probs = sigmoid(grid_points.dot(theta)).reshape(xx.shape)

# Contour decision boundary at probability = 0.5
plt.contour(xx, yy, probs, levels=[0.5], colors='black', linewidths=2)

# Manual line formula
b0 = theta[0][0]
b1 = theta[1][0]
b2 = theta[2][0]

x_vals = np.linspace(X[:,0].min(), X[:,0].max(), 200)
y_vals = -(b0 + b1 * x_vals) / b2

plt.plot(x_vals, y_vals, 'k--', label="Decision Boundary (Manual)")

plt.xlabel("Study Load (scaled)")
plt.ylabel("Sleep Quality (scaled)")
plt.title("Logistic Regression Decision Boundary (No sklearn)")
plt.legend()
plt.show()

"""#logistic Regression ( confusion matrix)
  
"""

import numpy as np
import matplotlib.pyplot as plt


# 1. Predict Using Trained Logistic Model

def predict(X, theta):
    return (sigmoid(X.dot(theta)) >= 0.5).astype(int)

y_pred = predict(X_b, theta)   # predicted labels
y_true = y                     # actual labels


# 2. Compute Confusion Matrix From Scratch

TP = np.sum((y_pred == 1) & (y_true == 1))
TN = np.sum((y_pred == 0) & (y_true == 0))
FP = np.sum((y_pred == 1) & (y_true == 0))
FN = np.sum((y_pred == 0) & (y_true == 1))

conf_matrix = np.array([[TP, FP],
                        [FN, TN]])

print("Confusion Matrix (from scratch):")
print(conf_matrix)


# 3. Calculate Accuracy, Precision, Recall

accuracy = (TP + TN) / len(y_true)
precision = TP / (TP + FP + 1e-9)
recall = TP / (TP + FN + 1e-9)

print(f"\nAccuracy:  {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")

# 4. Plot Confusion Matrix

plt.figure(figsize=(6,5))
plt.imshow(conf_matrix, cmap="Blues")

plt.title("Confusion Matrix (No sklearn)")
plt.colorbar()

# labels
plt.xticks([0,1], ["Predicted: High Stress", "Predicted: Low Stress"])
plt.yticks([0,1], ["Actual: High Stress", "Actual: Low Stress"])

# Add text inside boxes
for i in range(2):
    for j in range(2):
        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', fontsize=14, color='black')

plt.show()

# --- F1 SCORE FROM SCRATCH ---

precision = TP / (TP + FP + 1e-9)
recall = TP / (TP + FN + 1e-9)

f1_score = 2 * (precision * recall) / (precision + recall + 1e-9)

print(f"\nF1 Score (from scratch): {f1_score:.4f}")


# ROC CURVE FROM SCRATCH


# 1. Get predicted probabilities (sigmoid outputs)
probabilities = sigmoid(X_b.dot(theta))

# Prepare arrays
thresholds = np.linspace(0, 1, 200)
TPR_list = []
FPR_list = []

for th in thresholds:
    y_pred_th = (probabilities >= th).astype(int)

    TP = np.sum((y_pred_th == 1) & (y_true == 1))
    TN = np.sum((y_pred_th == 0) & (y_true == 0))
    FP = np.sum((y_pred_th == 1) & (y_true == 0))
    FN = np.sum((y_pred_th == 0) & (y_true == 1))

    TPR = TP / (TP + FN + 1e-9)
    FPR = FP / (TN + FP + 1e-9)

    TPR_list.append(TPR)
    FPR_list.append(FPR)

# Plot ROC
plt.figure(figsize=(7,6))
plt.plot(FPR_list, TPR_list, color="blue", label="ROC Curve")
plt.plot([0,1], [0,1], 'r--', label="Random Guess (Baseline)")
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("ROC Curve (from scratch)")
plt.legend()
plt.show()

"""2. KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay

model = KNeighborsClassifier()
model.fit(X_train, y_train)

preds = model.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, preds))

ConfusionMatrixDisplay.from_predictions(y_test, preds)

plt.title("KNN Confusion Matrix")
plt.show()

"""3. NA√èVE BAYES"""

from sklearn.naive_bayes import GaussianNB

model = GaussianNB()
model.fit(X_train, y_train)

preds = model.predict(X_test)
print("Naive Bayes Accuracy:", accuracy_score(y_test, preds))

ConfusionMatrixDisplay.from_predictions(y_test, preds)
plt.title("Naive Bayes Confusion Matrix")
plt.show()

"""4. SVM"""

from sklearn.svm import SVC

model = SVC()
model.fit(X_train, y_train)

preds = model.predict(X_test)
print("SVM Accuracy:", accuracy_score(y_test, preds))

ConfusionMatrixDisplay.from_predictions(y_test, preds)
plt.title("SVM Confusion Matrix")
plt.show()

"""5. XGBOOST"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Multi-class labels (0-4)
y = df["StressLevel"] - 1
X = df[["SleepQuality", "AcademicPerf", "StudyLoad", "Extracurricular"]]

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# XGBoost Multi-class
model = XGBClassifier(
    objective="multi:softmax",
    num_class=5,
    eval_metric="mlogloss"
)

model.fit(X_train, y_train)

preds = model.predict(X_test)
print("XGBoost Multi-class Accuracy:", accuracy_score(y_test, preds))

ConfusionMatrixDisplay.from_predictions(y_test, preds)
plt.title("XGBoost Confusion Matrix (Multi-class)")
plt.show()

""" COMPARE ALL CLASSIFICATION MODELS"""

# ---------------------------------------------------
# COMPARE ALL CLASSIFICATION MODELS
# ---------------------------------------------------

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# FIX CLASS LABELS IF STARTING FROM 1
y_fixed = np.array(y)
if y_fixed.min() == 1:
    y_fixed = y_fixed - 1

# SPLIT AGAIN WITH FIXED y
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y_fixed, test_size=0.2, random_state=42
)

# SCALE DATA
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# ---------------------------------------------------
# DEFINE ALL MODELS
# ---------------------------------------------------

from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier

models = {

    "KNN": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "SVM": SVC(),
    "XGBoost": XGBClassifier(eval_metric="logloss")
}

accuracies = {}


# ---------------------------------------------------
# TRAIN & EVALUATE ALL MODELS
# ---------------------------------------------------
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    accuracies[name] = acc
    print(f"{name}: {acc:.4f}")


# ---------------------------------------------------
# FIND BEST MODEL
# ---------------------------------------------------
best_model = max(accuracies, key=accuracies.get)
best_acc = accuracies[best_model]

print("\n--------------------------------------")
print(f" BEST MODEL: {best_model}  ")
print(f" BEST ACCURACY: {best_acc:.4f} ")
print("--------------------------------------")


# ---------------------------------------------------
# PLOT COMPARISON
# ---------------------------------------------------
plt.figure(figsize=(12, 6))
plt.bar(accuracies.keys(), accuracies.values())
plt.xticks(rotation=45, ha="right")
plt.ylabel("Accuracy Score")
plt.title("Comparison of Classification Algorithms")
plt.tight_layout()
plt.show()

"""#MERGED COMPARISON GRAPH (Regression + Classification Models)"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ------------------------------
# MERGED MODEL PERFORMANCE TABLE
# ------------------------------

comparison_all = pd.DataFrame({
    "Model": [
        "Simple Linear Regression",
        "Multiple Linear Regression",
        "Polynomial Regression",
        "Decision Tree Regression",
        "Random Forest Regression",
        "Logistic Regression",
        "KNN Classifier",
        "Naive Bayes",
        "SVM Classifier",
        "XGBoost Classifier"
    ],

    "R¬≤ Score": [
        0.121, 0.136, 0.146, 0.372, 0.684,
        None, None, None, None, None
    ],

    "RMSE": [
        1.257, 1.2467, 1.2394, 1.0957, 0.777,
        None, None, None, None, None
    ],

    "Accuracy": [
        None, None, None, None, None,
        0.8017, 0.4310, 0.7155, 0.8621, 0.8707
    ]
})

# Convert RMSE (lower=better) into RMSE_score (higher=better)
max_rmse = comparison_all["RMSE"].max()
comparison_all["RMSE (Inverted)"] = max_rmse - comparison_all["RMSE"]

# Melt dataset for combined graph
melt_df = comparison_all.melt(
    id_vars="Model",
    value_vars=["R¬≤ Score", "RMSE (Inverted)", "Accuracy"],
    var_name="Metric",
    value_name="Value"
)

# ------------------------------
# COMBINED BAR CHART
# ------------------------------
plt.figure(figsize=(14,6))
sns.barplot(data=melt_df, x="Model", y="Value", hue="Metric", palette="Set2")

plt.title("Combined Comparison of Regression & Classification Models", fontsize=16)
plt.xticks(rotation=60, ha='right')
plt.ylabel("Performance Score (Higher = Better)")
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.tight_layout()
plt.show()

"""‚≠ê Regression Model : Random Forest Regression

Provides most accurate continuous stress score prediction.

‚≠ê Classification Model : XGBoost Classifier

Provides best high-stress vs low-stress classification.

‚úî Takes user input

‚úî Sends it to your trained Random Forest Regression model

‚úî Predicts the Stress Level (1‚Äì5)

‚úî Prints both the numeric value and the stress category (Low / Medium / High)

#Random Forest : user input
"""

#
#  USER INPUT ‚Üí PREDICT STRESS LEVEL + ADVICE


print("\n--- Student Stress Prediction System ---")

# Take user input
sleep = float(input("Enter Sleep Quality (1‚Äì5): "))
acad = float(input("Enter Academic Performance (1‚Äì5): "))
study = float(input("Enter Study Load (1‚Äì5): "))
extra = float(input("Enter Number of Extracurricular Activities (1‚Äì5): "))

# Convert to model input
user_input = np.array([[sleep, acad, study, extra]])

# Predict using Random Forest
predicted_stress = rf_model.predict(user_input)[0]

print("\n--------------------------------------------")
print(f" (1 = Low, 5 = High)\nPredicted Stress Level: {predicted_stress:.2f}")


# INTERPRETATION AND RECOMMENDATION

if predicted_stress < 2:
    level = "Very Low Stress üü¢"
    advice = "You're doing well!"

elif 2 <= predicted_stress < 2.7:
    level = "Low Stress üü°"
    advice = "Maintain healthy habits."

elif 2.7 <= predicted_stress < 3.4:
    level = "Moderate Stress üü†"
    advice = "Improve sleep & reduce workload."

elif 3.4 <= predicted_stress < 4.2:
    level = "High Stress üî¥"
    advice = "Reduce study load & take breaks."

else:
    level = "Very High Stress ‚ö†Ô∏è"
    advice = "Seek support immediately!"
2

print(f"Stress Category: {level}")
print(f"Recommendation: {advice}")
print("--------------------------------------------")

"""#XG-Boost Model : Input"""

import numpy as np

#  USER INPUT ‚Üí XGBoost Multi-class Prediction

print("\n---  Stress Level Predictor ---")

# Take user inputs
sleep = float(input("Enter Sleep Quality (1‚Äì5): "))
acad = float(input("Enter Academic Performance (1‚Äì5): "))
study = float(input("Enter Study Load (1‚Äì5): "))
extra = float(input("Enter Number of Extracurricular Activities (1‚Äì5): "))

# Prepare input array
user_input = np.array([[sleep, acad, study, extra]])

# XGBoost expects labels 0‚Äì4, so prediction + 1
predicted_class = int(model.predict(user_input)[0]) + 1

print("\n--------------------------------------------")
print(f"Predicted Stress Level: {predicted_class} (1 = Low, 5 = High)")


# Interpretation & Recommendation

if predicted_class == 1:
    category = "Very Low Stress üü¢"
    advice = "You are relaxed and stable. Maintain your routine."

elif predicted_class == 2:
    category = "Low Stress üü°"
    advice = "Everything seems manageable. Keep following healthy habits."

elif predicted_class == 3:
    category = "Moderate Stress üü†"
    advice = "Some stress is present. Improve sleep quality and reduce unnecessary workload."

elif predicted_class == 4:
    category = "High Stress üî¥"
    advice = "You are under high stress. Reduce study load, take breaks, and prioritize rest."

else:
    category = "Very High Stress ‚ö†Ô∏è"
    advice = "Immediate attention needed! Balance your workload and seek support if required."

print(f"Stress Category: {category}")
print(f"Recommendation: {advice}")
print("--------------------------------------------")

import joblib

joblib.dump(rf_model, "rf_model.pkl")
joblib.dump(model, "xgb_model.pkl")